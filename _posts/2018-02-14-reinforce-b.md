---
layout:     post
title:      The Policy of Truth
date:       2018-02-14 0:00:00
summary:    An outsider tour of reinforcement learning, Part 7. Policy gradient doesn't have gradients.
author:     Ben Recht
visible:    false
---

Our first generic candidate for solving reinforcement learning is _policy gradient_. Policy gradient is an incredibly attractive algorithm as it apparently lets one fine tune a program to solve any problem without any domain knowledge. Of course, anything that makes such a claim must be too general for its own good. Indeed, if you dive into it, policy gradient is nothing more than random search dressed up in mathematical symbols and lingo.

I apologize in advance that this is one of the more notation heavy posts. Policy gradient makes excessive use of notation to fool you into thinking there is something deeper going on than there really is. See if you can find the places where sleight of hand occurs.

Let's start with the super general problem that people solve with policy gradient. Recall that a _trajectory_ is a sequence of states and control actions generated by a dynamical system.
